\chapter{Experiments}\label{chap:experiments}

\section{Tools and Software Framework}

\todo[inline]{Some insight into which tools are used and why:}
\begin{itemize}
  \item briefly point to speed comparison results (own application specific comparison + official charts)
  \item prototyping speed C++ vs Julia (Python already out of the game: too slow, see first point)
  \item Julia: good, general framework provided: \texttt{POMDPs.jl}, an interface for
  defining, solving, and simulating discrete and continuous, fully and
  partially observable Markov decision processes.  \cite{egorov2017pomdps}
  There also exists a C++ framework, but this very verbose and not suitable for
  rapid prototyping (\url{http://bigbird.comp.nus.edu.sg/pmwiki/farm/appl/})
  \item conclusion: Julia \cite{bezanson2017julia}
\end{itemize}

\section{Simultaneous Localization and Planning}

\section{Motion Planning with Latent Human Intentions}

\section{Comparison}
\todo[inline]{This section will mainly contain the "lessons learned"
+ a comparison between the problems, explaining the mechanisms which lead to
the improvement in each case.}

\begin{itemize}
  \item \acp{pomdp} provide an elegant way of closing the loop between
    prediction (and perception models) and planning.
  \item This provides benefits through various mechanisms:
  \item Simultaneous localization and planning: Using a \ac{pomdp} leads to active
    information gathering and provides a principled, optimization based
    approach to solving this problem (even under massive uncertainty). Solving
    it without such procedure is not straightforward, since planning on expectation
    with these highly multi-modal belief topologies is impractical.
  \item Planning with latent human intentions: The \ac{pomdp} based solution
    allows the robot to consider future observations, making the robots plans
    less conservative because the agent knows that uncertainty about the humans intentions
    will be reduced in the future. For this very problem structure, neglecting future observations
    provides a principled way of solving this problem. Through this
    approximation, the problem is simplified to a problem that is still
    NP-hard, but well studied. Good heuristics exist, such that search is well guided to find results
    withing reasonable planning horizons. However, sacrificing performance (in
    particular for models with unbounded uncertainty like constant velocity).
    \begin{itemize}
      \item Future work: \ac{pomdp} solution method is safer than planning with
      probabilistic obstacles while reaching the goal in fewer number of steps.
      However, probabilistic obstacles can provide a-priory estimate of safety
      while for \acp{pomdp} this can only be shown empirically through large
      scale simulations. It would be nice to provide a safety assurance for
      this special type of \acp{pomdp} (Mixed Observability Markov Decision
      Process where the safety only depends on some unactuated decoupled part
      of the state.)
    \end{itemize}
\end{itemize}
