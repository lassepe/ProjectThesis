\chapter{Summary}\label{chap:summary}

This work examines the use of \acfp{pomdp} for planning in uncertain
environments in the context of robotics. At the example of two continuous-space
application domains we provide a detailed comparison of approximate numerical
\ac{pomdp} solutions to approaches based on problem specific simplifications.

We begin by reviewing some of the fundamentals of sequential decision making
under uncertainty. We introduce the theoretical framework of \acp{pomdp} and
present two state-of-the-art approximate online \ac{pomdp} solvers:
\acf{despot}, and \acf{pomcpow}. Furthermore, we briefly discuss our choice of
tools and software framework for modelling and solving
\acp{pomdp}.\\
Based on this theoretical introduction we examine the use of \acp{pomdp} for
robotic planning problems under uncertainty at the example of two problem
domains.\\
First, we study an instance of \emph{simultaneous localization and planning}.
For this application domain we systematically quantify the performance
advantage of \ac{despot} and \ac{pomcpow} with both analytic and empirical
heuristic guidance compared to two baselines derived from an approximate
version of the \ac{pomdp}. Our results show that behaviors generated by full
\ac{pomdp} approaches are significantly safer and allow the robot to reach its
goal faster when domain knowledge is integrated in a computationally efficient
manner. In a detailed analysis we discuss the mechanisms that give rise to the
observed performance advantage.\\
Subsequently, we study an instance of motion planning in a shared space with
a human whose intentions are unknown to the robot. For this purpose we
implement a software model to simulate interacting humans and robots with near
real time \ac{pomdp} planning capabilities. Using this framework, we make
a detailed comparison of \acf{psrp} proposed by
\cite{fisac2018probabilistically} to a \ac{pomcpow} approach. In
a comprehensive evaluation we observe marginally better performance of the full
\ac{pomdp} approach at the expense of higher planning time. We show that in
many scenarios \ac{psrp} provides a good approximation to the \ac{pomdp} and
discuss the cause of the remaining performance gap. In particular, we find that
\ac{pomcpow} achieves superior performance in cases where the human action is
not well explained by the planning model.

In conclusion, we can state that modern \ac{pomdp} solvers provide a generic
way to generating robust policies for optimized interaction with uncertain
robotic environments. Our results show that for both application domains
studied in this work, full \ac{pomdp} approaches outperform the common
baselines. A detailed comparison of \ac{psrp} to \ac{pomcpow} reveals that in
certain cases, large parts of the performance of a full \ac{pomdp} solution may
be recovered by a carefully designed problem specific approach.
