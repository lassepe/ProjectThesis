\chapter{Introduction}

The \textit{partially observable Markov decision process} (POMDP) provides
a principled general framework for planning in partially observable stochastic
environments. In contrast to their well known fully observable counter part,
the \textit{Markov Decision Process} (MDP), in a POMDP the agent can not access
state information directly. Instead, the agent is presented with observations
as stochastic emissions of the true state of the world. Therefore, solving
a POMDP requires the planner to reason about a distribution over possible
futures with uncertainty in both the transition and observation model. This
makes solving a POMDP a significantly more challenging problem than solving the
corresponding fully observable MDP.\\

A POMDP is a PSPACE-complete problem and thus optimal solutions to problems of
this class can not be found in polynomial time. Therefore, in robotics
applications, characterized by limited compute and real time constraints, POMDP
solution methods are traditionally avoided. Instead, simplifications are made
that neglect the partial observability or make other assumptions about the
problem structure.\\

This project aims to explore how despite these challenges the POMDP
framework can be used to compute robust policies for a robot to optimally
interact with an uncertain environment. For this purpose, uncertainty in
two different subsets of the state space are considered:\\
\textit{External States,}  states of the environment. (e.g. position of the
robot).\\
\textit{Internal States,} latent \textit{model parameters} of the
environment (e.g. intentions of other agents).\\

The use of POMDP solution methods for planning in the face of uncertainty in
each of these domains will be examined. External state uncertainty will be
studied in a simulated environment at the example of simultaneous localization
and planning. Internal state uncertainty will be studied at the example of
human robot interaction.\\
In order to address the issue of limited compute in the context of robotics
applications, this project will investigate how meta reasoning can be employed to
dynamically switch models during on-line planning in an effort to account for
the trade-off between accuracy and computational complexity when reasoning about
future environment states.
