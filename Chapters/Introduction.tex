\chapter{Introduction}\label{chap:introduction}


Many decision making problems are subject to inherent uncertainty. Examples of
such problems range from aircraft collision avoidance and robotic navigation
tasks to to applications in health care and medical treatment
\cite{kochenderfer2012next, bandyopadhyay2013intention, pineau2003towards,
schaefer2005modeling}. While humans have developed good intuition for decision
making problems present in their day to day lives, many of the same tasks --
like planning in autonomous driving -- pose difficult problems for robotic
agents \cite{levinson2011towards}.

Actively considering uncertainty in planning promises to improve robustness,
safety and performance of the system. In conventional control theory a typical
approach is to model uncertainty in terms of a bounded disturbance,
robustifying the controller through reasoning over worst case disturbance
sequences \cite{petersen2012robust}. However, modelling the disturbance as an
adversarial player is often impractical, since long tail distributions may
cause the controller to come up with overly conservative, thus poorly
performing plans.

Therefore, a tremendous amount of research has focused on incorporating
uncertainty in decision making through probabilistic models, rather than
adversarial game type approaches \cite{roy1999coastal, amato2015planning,
fisac2018probabilistically, choudhury2019dynamic}.

One of the most general frameworks for modeling uncertainty in sequential
decision making in a probabilistic fashion is provided by the \ac{pomdp}.
Formulating and solving a planning problem as a \ac{pomdp} allows the planner
to reason over both state and outcome uncertainty. Also, by taking into
account future observations, solving a \ac{pomdp} gives rise to behavior that actively performs information gathering.

\section{Motivation}\label{sec:motivation}

While \acp{pomdp} provide a comprehensive way of taking into account
uncertainty in the planning procedure, finding the optimal solution to these
problems is in practice often intractable since in worst case it cannot be
done in polynomial time \cite{papadimitriou1987complexity}.

Fundamentally different approaches....


Therefore, in robotics applications, characterized by limited compute and real
time constraints, \ac{pomdp} solution methods are traditionally avoided. domain
specific simplifications are made that neglect the partial observability or
make other assumptions about the problem structure \cite{sadigh2016information,
fisac2018probabilistically}. 


\todo[author=ZS]{It might be good to present this as
a choice between solving an approximate formulation of the POMDP or solving an
exact formulation approximately.}.

Recent progress in \ac{pomdp} research has yielded new solution methods that
have been shown to provide good performance even on medium to large scale
\acp{pomdp} \cite{somani2013despot,sunberg2018online}. Additionally, the
introduction of \pomdpsjl \cite{egorov2017pomdps} -- a modern framework for
modelling and solving \acp{pomdp} in the Julia programming language -- has
lowered the barrier to modelling problems as \acp{pomdp} by abstracting away
a lot of the complexity.

Motivated by these advances this work aims to provide insight into the use of
\acp{pomdp} for modelling and solving planning problems in robotics. At the
example of two application domains we examine the behaviors generated by this
kind of reasoning.\\

\section{Contribution}\label{sec:contribution}

\todo[inline]{
1. Systematically quantified the performance advantage of approximate numerical POMDP solutions with both analytic and empirical heuristic guidance compared to approximate problem formulations in two continuous-space problem domains.

2. Compared the approach by Fisac et al. (the RSS paper) to a POMDP solution and observed marginally better performance with the POMDP formulation.

3. Implemented a software model of interacting humans and drones with (near?) real time POMDP planning capability.

I'm not sure that I understand the "guide" contribution that you mentioned, can you clarify what the "guide" teaches people? I think it is actually not that common to compare "full POMDP" solutions vs approximations; people usually just say "POMDPs are intractable", so that is perhaps the angle to shoot for when outlining contributions.
}

First, we focus on \emph{simultaneous localization and
planning}, a problem characterized by inherent uncertainty in the physical
state of the robot. We use this example to provide insight into the steps
involved when setting up a problem as a \ac{pomdp}. We show how
domain knowledge can be used to adapt generic state-of-the-art \ac{pomdp}
solvers to a specific planning problem. Furthermore, we present two baselines
that may be used instead of a full \ac{pomdp} solution. Finally, we compare the
performance of all strategies and discuss the mechanisms through which
\ac{pomdp} solution methods are able to outperform the baseline approaches.\\
As a second application example we study an instance of motion planning in
a shared space with a human actor. In this problem, latent human intentions
force the agent to consider uncertainty in order to reach its goal safely. For
this problem, a sophisticated domain specific solution method has been
proposed, that avoids the complexity of a full \ac{pomdp} solution
\cite{fisac2018probabilistically}. We examine this second application domain to
provide a direct comparison of a generic \ac{pomdp} solver to a well engineered
domain specific approach. This comparison aims to show how well a problem may
be solved without considering the full complexity of \acp{pomdp} and to which
extent such an approximation can not keep up with the generic approach.

\section{Outline}
\todo[inline]{write, when structure has converged}

\begin{description}
  \item[Theory] Theoretical properties and background of POMDPs. Solution methods: POMCPOW, DESPOT.
  \item[Experiments] Applications of POMDPs to two problem domains: Simultaneous localization an planning, Motion planning with latent human intentions.
  \item[Summary] The summary of this work.
\end{description}
