\chapter{Introduction}\label{chap:introduction}


Many decision making problems are subject to inherent uncertainty. Examples of
such problems range from aircraft collision avoidance and robotic navigation
tasks to applications in health care and medical treatment
\cite{kochenderfer2012next, bandyopadhyay2013intention, pineau2003towards,
schaefer2005modeling}. While humans have developed good intuition for decision
making problems present in their day to day lives, many of the same tasks --
like planning in autonomous driving -- pose difficult problems for robotic
agents \cite{levinson2011towards}.

Actively considering uncertainty in planning promises to improve robustness,
safety and performance of the system. In conventional control theory a typical
approach is to model uncertainty in terms of a bounded disturbance,
robustifying the controller through reasoning over worst case disturbance
sequences \cite{petersen2012robust}. However, modelling the disturbance as an
adversarial player is often impractical, since long tail distributions may
cause the controller to come up with overly conservative, thus poorly
performing plans.

Therefore, a tremendous amount of research has focused on incorporating
uncertainty in decision making through probabilistic models, rather than
adversarial game type approaches \cite{roy1999coastal, amato2015planning,
fisac2018probabilistically, choudhury2019dynamic}.

One of the most general frameworks for modeling uncertainty in sequential
decision making in a probabilistic fashion is provided by the \ac{pomdp}.
Formulating and solving a planning problem as a \ac{pomdp} allows the planner
to reason over both state and outcome uncertainty. Also, by taking into account
future observations, solving a \ac{pomdp} gives rise to behavior that actively
performs information gathering.

While \acp{pomdp} provide a comprehensive way of taking into account
uncertainty in the planning procedure, finding the optimal solution to these
problems is in practice often intractable since in worst case it cannot be done
in polynomial time \cite{papadimitriou1987complexity}. However, there exists
a wide range of approximate strategies to compute useful solutions to these
problems. In this work, we distinguish between two fundamentally different
approaches to approximation: Solving an \emph{exact formulation} of the
\ac{pomdp} approximately; or finding an \emph{approximate formulation} of the
\ac{pomdp} to design a problem specific solver for the simplified domain. For
the sake of conciseness, we henceforth refer to the former as \emph{full
\ac{pomdp} solutions} while the latter are denoted as \emph{problem specific
simplifications}.

\section{Motivation}\label{sec:motivation}

In robotics applications, characterized by limited compute and real time
constraints, full \ac{pomdp} solution methods are traditionally avoided.
Instead, domain specific simplifications are used that neglect the partial
observability or make other assumptions about the problem structure
\cite{sadigh2016information, fisac2018probabilistically}. These simplifications
are typically justified by the assumption that a full \ac{pomdp} solution is
intractable. Furthermore, the implementation complexity of state-of-the-art
\ac{pomdp} solvers inhibits the adaption of these algorithms.

However, recent progress in \ac{pomdp} research has yielded new solution methods that
have been shown to provide good performance even on medium to large scale
\acp{pomdp} \cite{somani2013despot,sunberg2018online}. Additionally, the
introduction of \pomdpsjl \cite{egorov2017pomdps} -- a modern framework for
modelling and solving \acp{pomdp} in the Julia programming language -- has
lowered the barrier to modelling problems as \acp{pomdp} by abstracting away
large parts of the implementation complexity.

Motivated by these advances this work aims to provide insight into the use of
\acp{pomdp} for modelling and solving planning problems in robotics.

\section{Contributions}%
\label{sec:contributions}

At the example of two application domains we examine the use of behaviors
generated by state-of-the-art \ac{pomdp} solvers for robotic planning problems.
Specifically, this work contains the following contributions:

First, we systematically quantify the performance advantage of full
\ac{pomdp} solutions with both analytic and empirical heuristic guidance
compared to problem specific simplifications in a continuous-space problem
domains. For this purpose we focus on \emph{simultaneous localization and
planning}, a problem characterized by inherent uncertainty in the physical
state of the robot.

The second contribution is a detailed comparison of the problem specific
planning approach by \cite{fisac2018probabilistically} to a state-of-the-art
\ac{pomdp} solver. This comparison aims to show how well a problem may be
solved without considering the full complexity of \acp{pomdp} and to which
extent such an approximation can not keep up with the full \ac{pomdp} solution.
For this purpose we study an instance of motion planning in a shared space with
a human actor. In this application domain, latent human intentions force the
agent to consider uncertainty in order to reach its goal safely.

Finally, as part of our work on motion planning with latent human intentions
we contribute an implementation of a software model to simulate
interacting humans and robots with near real time \ac{pomdp} planning
capabilities. This implementation is designed to accommodate convenient
interchangeability of different human models and builds upon \pomdpsjl to allow
for a direct comparison of different planning approaches.

\section{Outline}
\todo[inline]{write, when structure has converged}

\begin{description}
  \item[Theory] Theoretical properties and background of POMDPs. Solution methods: POMCPOW, DESPOT.
  \item[Experiments] Applications of POMDPs to two problem domains: Simultaneous localization an planning, Motion planning with latent human intentions.
  \item[Summary] The summary of this work.
\end{description}
