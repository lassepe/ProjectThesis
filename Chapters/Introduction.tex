\chapter{Introduction}\label{chap:introduction}

Many decision making problems in robotics are subject to inherent uncertainty.
Examples of such problems range from aircraft collision avoidance and
navigation tasks to multi-agent-interaction
\cite{kochenderfer2012next}.\todo{cite} While humans have developed good
intuition for decision making problems present in their day to day lives, many
of the same tasks -- like planning in autonomous driving -- pose difficult
problems for robotic agents \cite{levinson2011towards}.

Actively considering uncertainty in planning promises to improve robustness,
safety and performance of the system. In conventional control theory\todo{what
is a better word for this?} a typical approach is to model uncertainty in terms
of a bounded disturbance, robustifying the controller through reasoning over
worst case disturbance sequences. However, modelling the disturbance as an
adversarial player is often impractical, since long tail distributions may
cause the controller to come up with overly conservative, thus poorly
performing plans.\todo{cite}

Therefore, a tremendous amount of research has focused on incorporating
uncertainty in decision making through probabilistic models, rather than
adversarial game type approaches \cite{roy1999coastal, amato2015planning,
fisac2018probabilistically, choudhury2019dynamic}.

\todo[inline]{Rather?: A principled general framework ...} One of the most
general framework for modeling uncertainty in sequential decision making in
a probabilistic fashion is provided by the \ac{pomdp}. Formulating and solving
a planning problem as a \ac{pomdp} allows the planner to reason over both,
state and outcome uncertainty. Also, by taking into account future
observations, solving a \ac{pomdp} gives rise to behavior through computation
that actively performs information.

While \acp{pomdp} provide a comprehensive way of taking into account
uncertainty in the planning procedure, finding the optimal solution to these
problems is in practice often intractable since in worst case it can not be
done in polynomial time.\todo{too sloppy?} Therefore, in robotics applications,
characterized by limited compute and real time constraints, \ac{pomdp} solution
methods are traditionally avoided. Instead, simplifications are made that
neglect the partial observability or make other assumptions about the problem
structure \cite{sadigh2016information, fisac2018probabilistically}.\todo{still
not happy with this paragraph}

This work aims to provide insight into the use of \acp{pomdp} for modelling and
solving planning problems in robotics in an effort to compute robust policies
for optimal interaction with uncertain environments. We show how this
methodology provides solutions to problems where uncertainty otherwise, either
keeps engineers from solving them in a principled manner or forces them to make
simplifications that compromise performance and robustness.


\todo[inline]{not too happy with this part, motivation has to be formulated precisely.}

We look at two application domains where uncertainty affects decision making
in different ways. First, we focus on simultaneous localization and
planning, a problem characterized by inherent uncertainty in the physical state
of the robot.

Subsequently, we examine motion planning in a shared space with a human agent
where uncertainty forces the robot to reason over the latent human behavior
model. We compare the performance of our provided solution to a domain specific
approximation provided by \cite{fisac2018probabilistically} and discuss the mechanisms
through which \acp{pomdp} improve the agent performance in this domain.

\begin{itemize}
  \item we discuss the mechanisms which make considering uncertainty important
  \item ... and discuss the differences between the two problems.
\end{itemize}


% TODO: remove
%
% For this purpose, uncertainty in two different subsets of the state space are
% considered: \emph{External States,}  states of the environment. (e.g. position
% of the robot). \emph{Internal States,} latent \emph{model parameters} of the
% environment (e.g. intentions of other agents).
% 
% In order to address the issue of limited compute in the context of robotics
% applications, this project will investigate how meta reasoning can be employed to
% dynamically switch models during on-line planning in an effort to account for
% the trade-off between accuracy and computational complexity when reasoning about
% future environment states.

\section{Chapter Outline}

\todo[inline]{write, when structure has converged}

\begin{description}
  \item[Theory] Theoretical properties and background of POMDPs. Solution methods: POMCPOW, DESPOT.
  \item[Applications] Applications of POMDPs to two problem domains: Simultaneous localization an planning, Motion planning with latent human intentions.
  \item[Summary] The summary of this work.
\end{description}
