\chapter{Introduction}\label{chap:introduction}

Many decision making problems in robotics are subject to inherent uncertainty.
Examples of such problems range from aircraft collision avoidance and
navigation tasks to multi-agent-interaction
\cite{kochenderfer2012next}.\todo{cite} While humans have developed good
intuition for decision making problems present in their day to day lives, many
of the same tasks -- like planning in autonomous driving -- pose difficult
problems for robotic agents \cite{levinson2011towards}.

Actively considering uncertainty in planning promises to improve robustness and
safety of the system. In conventional control theory\todo{what is a better word
for this?} a typical approach is to model uncertainty in terms of a bounded
disturbance, robustifying the controller through reasoning over worst case
disturbance sequences. However, modelling the disturbance as an adversarial
player is often impractical, since long tail distributions may cause the
controller to come up with overly conservative, thus poorly performing
plans.\todo{cite}

Therefore, a tremendous amount of research has focused on incorporating
uncertainty in decision making through probabilistic models, rather than
adversarial game type approaches \cite{roy1999coastal, amato2015planning,
fisac2018probabilistically, choudhury2019dynamic}.

\todo[inline]{Rather?: One of the most general frameworks ...} A principled
general framework for modeling uncertainty in sequential decision making is
provided by the \ac{pomdp}. Formulating and solving a planning problem as
a \ac{pomdp} allows the planner to reason over both, state and outcome
uncertainty. Also, by taking into account future observations, solving
a \ac{pomdp} gives rise to behavior through computation that actively performs
information.

However, finding the optimal solution to a \ac{pomdp} is in practice often
intractable since in worst case it can not be done in polynomial time.\todo{too
sloppy} Therefore, in robotics applications, characterized by limited compute
and real time constraints, \ac{pomdp} solution methods are traditionally
avoided. Instead, simplifications are made that neglect the partial
observability or make other assumptions about the problem structure
\cite{sadigh2016information, fisac2018probabilistically}.\todo{still not happy with this paragraph}

\todo[inline]{modify, state motivation more clearly}
\begin{itemize}
  \item very brief summary what this work is going to show / what is the point
        of this work and motivation for doing so.
\end{itemize}

This project aims to explore how despite these challenges the \ac{pomdp}
framework can be used to compute robust policies for a robot to optimally
interact with an uncertain environment. For this purpose, uncertainty in
two different subsets of the state space are considered:\\
\emph{External States,}  states of the environment. (e.g. position of the
robot).\\
\emph{Internal States,} latent \emph{model parameters} of the
environment (e.g. intentions of other agents).\\

The use of \ac{pomdp} solution methods for planning in the face of uncertainty in
each of these domains will be examined. External state uncertainty will be
studied in a simulated environment at the example of simultaneous localization
and planning. Internal state uncertainty will be studied at the example of
human robot interaction.\\
In order to address the issue of limited compute in the context of robotics
applications, this project will investigate how meta reasoning can be employed to
dynamically switch models during on-line planning in an effort to account for
the trade-off between accuracy and computational complexity when reasoning about
future environment states.

\section{Chapter Outline}

\todo[inline]{write, when structure has converged}

\begin{description}
  \item[Theory] Theoretical properties and background of POMDPs. Solution methods: POMCPOW, DESPOT.
  \item[Applications] Applications of POMDPs to two problem domains: Simultaneous localization an planning, Motion planning with latent human intentions.
  \item[Summary] The summary of this work.
\end{description}
